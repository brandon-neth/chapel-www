[welcome1]
  title="Welcome/Introduction"
  authors="Brandon Neth"
  description="Opening session to welcome participants and share the schedule for the day."
  start="9:00"
  end="9:10"

[welcome3]
  title="Welcome/Introduction"
  authors="Brandon Neth"
  description="Opening session to welcome participants and share the schedule for the day."
  slides="https://www.google.com"
  start="9:00"
  end="9:10"

[transformers]
  title="Transformers from Scratch"
  authors="Thitrin Sastarasadhit and Kenjiro Taura"
  description=""
  start="9:10"
  end="9:30"
  session="AI/ML"


[chai]
  title="ChAI: A Machine Learning Library in Chapel"
  authors="	Iain Moncrief"
  description="""
  Modern hardware is parallel in a multitude of ways, including
multi-core, multi-GPU, and multi-node paral- lelism. The
Chapel language provides a unified toolbox to make use
of these varying kinds of parallelism, and thus effectively
leverage computing hardware. One area that can benefit
from parallelization is ma- chine learning (ML), which has
grown in popularity in recent years. To explore Chapel’s
suitability for ML, over the course of a summer internship
project, the Chapel team has developed the first machine
learning framework in pure Chapel called ChAI. ChAI is
capable of training and inference, and is able to load pretrained models from PyTorch and apply them to workloads
distributed over any number of nodes, CPU cores, and GPUs.
The framework has shown promising scaling results; using
ChAI to load the MNIST model and classify 10,000 images, we
measured a 105x speedup when scaling from a single node to
128 nodes on a Cray XC machine. We plan to integrate ChAI
into the Chapel-powered Arkouda data science framework,
enabling interactive, ML-enabled data science over massive
datasets."""
  start="9:25"
  end="9:45"

[break3_1]
  title="Break"
  authors=""
  description=""
  start="9:45"
  end="10:00"
  
[hipermotif]
  title="HiPerMotif: Novel Parallel Subgraph Isomorphism in Large-Scale Property Graphs"
  authors="Mohammad Dindoost, Bartosz Bryg, Ioannis Koutis, David Bader and Oliver Alvarado Rodriguez"
  description="""
  We present HiPerMotif, a hybrid parallel algorithm for subgraph isomorphism addressing scalability limitations in largescale property graphs. Traditional vertex-by-vertex algorithms struggle with extensive early-stage exploration and limited
parallelization. HiPerMotif shifts search initialization through: (1) structural reordering prioritizing high-degree vertices, (2)
systematic first-edge mapping identification, (3) efficient validation, and (4) state injection at depth 2. Implemented in Chapel
within the Arachne framework, HiPerMotif achieves up to 66× speedup over state-of-the-art baselines and processes massive
datasets like the H01 connectome (150M edges) that existing methods cannot handle."""
  start="10:00"
  end="10:10"

[accelerating]
 title="Accelerating Probabilistic Inference of Hypergraph Algorithms Using PGAS and Chapel"
  authors="Rinor Ramli"
  description="""
  This presentation begins with a brief introduction on probabilistic inference for solving
hypergraph algorithms alongside its apparent strengths and challenges in implementation.
PGAS as natively provided by Chapel is then presented as a way to accelerate probabilistic
inference."""
  start="10:10"
  end="10:30"

[break3_2]
  title="Break"
  authors=""
  description=""
  start="10:30"
  end="10:45"

[keynote]
  title="Keynote: ..."
  authors="Chris Rackakous"
  description="..."
  start="10:45"
  end="11:45"

[break3_3]
  title="Break"
  authors=""
  description=""
  start="11:45"
  end="12:00"

[arkouda]
  title="Arkouda Bulletin: A Year of Progress in Exploratory Data Analytics at Scale"
  authors="Amanda Potts and Engin Kayraklıoğlu"
  description="""
  Arkouda (https://arkouda-www.github.io/) is	an	open-source,	NumPy-like	framework	for	
distributed	exploratory	data	analysis	(EDA),	built	on	a	Chapel	backend,	with	growing	
support	for	pandas-like	data	structures	and	operations.	Over	the	past	year,	the	project	has	
matured	substantially	through	major	architectural	improvements,	expanded	data	type	
support,	and	closer	alignment	with	the	evolving	NumPy	2.0	ecosystem.	These	updates	
enhance	expressiveness,	performance,	and	reliability	for	large-scale,	interactive	data	
science	workflows.

We	will	begin	with	a	general	introduction	to	Arkouda	and	highlight	recent	use	cases	and	
success	stories.	Given	the	number	of	Arkouda-related	talks	at	past	ChapelCon	events,	the	
remainder	of	the	session	will	focus	on	key	improvements	made	since	the	last	ChapelCon."""
  start="12:00"
  end="12:30"

[champs]
  title="ChapelCon ’25: Recent Developments in the CHApel MultiPhysics Simulation Software"
  authors="Anthony Chrun, Baptiste Arnould, Karim Zayni, Guillaume Auger, Maxime Blanchet, Eric Laurendeau and Justin Rigal"
  description="""
  CHAMPS (CHapel MultiPhysics Software) is a multiphysics computational framework built
around an aerodynamic flow solver based on the Euler and Reynolds-Averaged Navier–Stokes
(RANS) equations, currently under development at Polytechnique Montreal. Since its early ´
development, multiple research efforts have contributed to enhancing its capabilities by incorporating a range of turbulence and transition models. Additional physics modules include
solvers for droplet trajectory prediction, ice accretion, condensation trail formation, structural
deformation, and fluid–structure interaction. This paper presents some of the most recent and
impactful advancements achieved within CHAMPS, in order to share them with the Chapel
community.
"""
  start="12:30"
  end="13:00"

[break3_4]
  title="Break"
  authors=""
  description=""
  start="13:00"
  end="13:15"

[autodiff]
  title="Automatic Differentiation in Chapel"
  authors="Luca Ferranti"
  description="""
  Automatic differentiation is the secret sauce allowing neural networks, and machine learning
applications in general, to be more than just maths, but actually work!
This talk will start with a brief general overview of automatic differentiation, then dive into
two concrete workstreams.

ForwardModeAD is a Chapel library for forward-mode automatic differentiation, built using
operator overloading. In the first half of the talk, I’ll share the story behind its development
— the design choices, the Chapel language features that made it possible, and the trade-offs
along the way. I will also cover performance bottlenecks, current limitations, and where the
library is headed next.

Enzyme is a library for automatic differentiation at the LLVM level. It has already been
integrated into languages like Julia and Rust, often achieving higher performance than nativelanguage frameworks. In the second half of the talk, I’ll present my work on integrating
Enzyme with Chapel, showing the current status, limitations, challenges encountered, and
next steps.
"""
  start="13:15"
  end="13:35"

[multigpu]
  title="A Portable Low-Level Multi-GPU Branch-and-Bound: A Comparison Against Chapel"
  authors="Ivan Tagliaferro de Oliveira Tezoto, Guillaume Helbecque, Ezhilmathi Krishnasamy, Nouredine Melab and Gregoire Danoy"
  description=""
  start="13:35"
  end="13:55"

[cloud]
  title="Running Chapel on the Cloud"
  authors="Benson Muite"
  description=""
  start="13:55"
  end="14:00"

[discussion]
  title="Open Community Discussion"
  authors=""
  description=""
  start="14:00"
  end="??"

[welcome2]
  title="Welcome"
  authors=""
  description=""
  start="9:00"
  end="9:05"

[state]
  title="State of the Project: Brad"
  authors="Brad Chamberlain"
  description=""
  start="9:05"
  end="9:35"

[invited_lumi]
  title="Invited: LUMI"
  authors=""
  description=""
  start="9:35"
  end="10:05"

[break4_1]
  title="Break"
  authors=""
  description=""
  start="10:05"
  end="10:20"

[recursion]
  title="Recursion and slicing impacts on performance in Chapel, C, and Fortran"
  authors="Nelson Luís da Costa Dias"
  description="A simple (serial) recursive summation over a 1-dimensional array (à là quicksort) was implemented in 3 languages (Chapel, C, Fortran) and 4 compiler variants (Chapel 2.5 with LLVM, gcc 13.3.0, clang 18.1.3, gfortran 13.3.0), and compared with a standard non-recursive summation. Two alternatives for the recursion were tested: (i) by passing array indices explicitly in the recursion (possible in all three languages) and (ii) by using array slicing (only possible in Chapel and Fortran). Performance varied widely. Clang and Chapel were faster for the standard non-recursive summation; C and Fortran were faster for recursion using indices; and Fortran was much faster than Chapel for recursion using array slices. The performance of Chapel slices is a known issue (https://chapel.discourse.group/t/ new-issue-improve-the-performance-of-slices-and-rank-change-operations/30503). It appears that for the standard summation and recursive summation using indices the performance is related to the backend, i.e. GCC (gfortran and gcc) versus LLVM (Chapel and clang)."
  start="10:20"
  end="10:30"

[vectorlib]
  title="Unlocking Portable and Performant Vector Programming with chpl Vector Library"
  authors="Jade Abraham"
  description="""
When writing thread-parallel applications, users of Chapel can use high-level productivity 
features like ‘forall’ and promotion to succinctly express their algorithms or use lower-level 
features like ‘begin’to more directly control task creation. Chapel’s GPU support is similar, 
where high-level promoted statements can become kernels, but explicit ‘foreach’ loops 
can be used for greater control over the generated kernel. A missing piece to this is with 
instruction level parallelism and vectorization. The Chapel compiler usually does a great 
job at automatically vectorizing code, but when it fails there is no recourse. The next best 
option is to interoperate with C or Fortran code to write the low-level operations. 
In order to solve this problem, I have created CVL: chpl Vector Library. This library exposes 
a vector type as a first class object which provides a unified set of operations across x86 
and ARM. This provides Chapel developers direct control over the vectorization in their 
applications. In this demo, I will showcase the design and implementation of the library, 
including the tools used to maintain it. I will then demonstrate several benchmarks where 
usage of CVL beats the Chapel compiler’s auto-vectorization. Lastly, I will discuss potential 
improvements for the library going forward.
"""
  start="10:30"
  end="10:50"

[break4_2]
  title="Break"
  authors=""
  description=""
  start="10:50"
  end="10:55"

[typelevel]
  title="Type-Level Programming in Chapel for Compile-Time Specialization"
  authors="Daniel Fedorin"
  description="""
  Chapel’s type system can be surprisingly powerful. In addition to “usual” features such as
generics and polymorphism, Chapel provides the ability to manipulate types using functions;
this involves both taking types as arguments to functions and returning them from these
functions. This can enable powerful programming techniques that are typically confined to the
domain of metaprogramming.
For example, although Chapel’s notion of compile-time values — ‘param’s — is limited to
primitive types such as integers, booleans, and strings, one can encode compile-time lists of
these values as types. Such encodings can be used to create compile-time specializations of
functions that would be otherwise tedious to write by hand. One use case for such
specializations is the implementation of a family of functions for approximating differential
equations, the Adams-Bashforth methods. Some variants of these methods can be encoded
as lists of coefficients. Thus, it becomes possible to define a single function that accepts a
type-level list of coefficients and produces a “stamped out” implementation of the
corresponding method. This reduces the need to implement each method explicitly by hand.
Another use case of function specialization is a type-safe ‘printf’ function that validates that
users’ format specifiers match the type of arguments to the function.
More generally, Chapel’s types can be used to encode algebraic sums (disjoint unions) and
products (Cartesian) of types. This, in turn, makes it possible to build arbitrary data structures
at the type level. The lists-of-values case above is an instance of this general principle.
Functions can be defined on type-level data structures by relying on overloading and type
arguments. Programming in this manner starts to resemble programming in a purely functional
language such as Haskell.
Though this style of programming has not seen much use thus far, it can be a powerful
technique for controlling types of arguments or constructing highly customized functions with
no runtime overhead.
"""
  start="10:55"
  end="11:15"

[pythonlike]
  title="If it walks like Python and quacks like Python, it must be….Chapel?"
  authors="Jade Abraham and Lydia Duncan"
  description="""
  Interoperability is a key tool for new languages to drive adoption and grow. Chapel has a
rich set of interoperability features that allow users to write flexible applications. For
example, the ability to write C code inline with Chapel code reaches the peak of
interoperability - writing code from two languages side by side in the same file. When it
comes to interoperability with Python, Chapel has taken a similar approach to other
languages. Python is a slow language by its very nature and to achieve good performance
modules are written in another language that is then called from Python code. Chapel has
been able to fill this role for some time. This takes a Python first approach, working well for
those who want to primarily write Python and a little bit of Chapel.
The ability to call Python code from Chapel allows a Chapel programmer to write the
majority of their application in Chapel and use a little bit of Python. Recent work has
resulted in a Python module for Chapel that allows developers to reach the gold standard
of interoperability, Python and Chapel code side-by-side in the same file. In this demo, we
will showcase how this module is put together and some of the key features that enable
Python interoperability in multiple ways. We will also show some applications areas where
this can be useful with libraries like numpy, scipy, and pandas."""
  start="11:15"
  end="11:35"

[formal]
  title="Using Formal Methods to Discover a Bug in the Chapel Compiler"
  authors="Daniel Fedorin"
  description="""
  Formal methods are a set of techniques that are used to validate the correctness of software. A
particular category of these methods, model checking, uses the mathematical language of
temporal logic to construct specifications of software’s behavior. A solver can then validate the
constraints described in the formal language and ensure that undesirable states do not occur.
This talk will be an experience report of using formal methods, specifically the Alloy analyzer, to
detect a bug in Chapel’s ‘Dyno’ compiler front-end library. The area in which the bug was
discovered is currently used in production, as well as a part of editor tools such as chplcheck
and chpl-language-server.
Specifically, Alloy was used to construct a formal specification of a part of Chapel’s use/import
lookup algorithm. Chapel has a number of complicated scoping rules and possible edge cases
in this area. By running this specification against a solver, a sequence of steps was discovered
that could cause the algorithm to malfunction and produce incorrect results. A program that
causes these steps to occur was constructed and served as a concrete reproducer for the bug.
This reproducer was used to adjust the logic and fix the bug.
This talk will cover the fundamentals of temporal logic required for formal specifications, the
necessary parts of Chapel’s use/import lookup algorithm, and the steps taken to encode and
validate the compiler’s behavior."""
  start="11:35"
  end="11:45"

[julia]
  title="Chapel Julia interoperability"
  authors=""
  description=""
  start="11:45"
  end="11:45"

[break4_3]
  title="Break"
  authors=""
  description=""
  start="11:45"
  end="12:00"

[sorting]
  title="Distributed-Memory Sorting in the Chapel Standard Library"
  authors="	Michael Ferguson"
  description=""
  start="12:00"
  end="12:20"

[radix]
  title="Comparing Distributed-Memory Programming Frameworks with Radix Sort"
  authors="Shreyas Khandekar and Matt Drozt"
  description="""
  Distributed-memory parallel processing addresses computational problems requiring
significantly more memory or computational resources than can be found on one node.
Software written for distributed-memory parallel processing typically uses a distributedmemory parallel programming framework to enhance productivity, scalability, and
portability across super-computers and cluster systems.
These frameworks vary in their capabilities and support for managing communication and
synchronization overhead to achieve scalability. We implemented a communicationintensive distributed radix sort algorithm to examine and compare the performance,
scalability, usability, and productivity diFerences between five distributed-memory parallel
programming frameworks: Chapel, MPI, OpenSHMEM, Conveyors, and Lamellar. """
  start="12:20"
  end="12:40"

[break4_4]
  title="Break"
  authors=""
  description=""
  start="12:40"
  end="12:50"

[invited_todd]
  title="Invited: Todd?"
  authors=""
  description=""
  start="12:50"
  end="13:50"

[break4_5]
  title="Break"
  authors=""
  description=""
  start="13:50"
  end="14:00"

[repartitioning]
  title="Repartitioning for Performance: Flexible Data Movement in Chapel"
  authors="Ryan Keck"
  description="""
  Many parallel algorithms depend on reshaping how data is distributed across locales to
achieve efficient computation. In this talk, I’ll introduce the Repartition module, a custom
module implemented in Chapel designed to simplify and generalize all-to-all
communication patterns. It enables each locale to specify a destination locale for each list
element, then automatically redistributes the data accordingly.
I’ll show how this module enables sharding patterns useful across a range of distributed
algorithms. We’ll look at how Repartition integrates with Chapel’s parallelism features,
explore implementation tradeoffs, and share benchmark results across various workloads.
Whether you're writing high-performance algorithms or building reusable distributed
libraries, Repartition offers a flexible and powerful tool for managing data layout.
"""
  start="14:00"
  end="14:10"

[nvshmem]
  title="Efficient Multi-GPU Communication with NVSHMEM in Chapel"
  authors="Sosuke Hosokawa and Kenjiro Taura"
  description="""
  While Chapel’s GPU programming model simplifies multi-GPU
programming, it does not fully exploit the advanced GPU-to-GPU
communication capabilities provided by modern GPUs. We present
an integration of NVSHMEM into Chapel to enable efficient GPUto-GPU communication from within CUDA kernels. Our implementation modifies Chapel’s GPU build pipeline and runtime system to
support NVSHMEM’s symmetric memory model. Performance evaluation on the Miyabi supercomputer shows up to 100x speedup for
small transfers and effective utilization of interconnect bandwidth
for larger transfers compared to Chapel’s native copy operations.
"""
  start="14:10"
  end="14:20"

[aggregation]
  title="Towards A General Aggregation Framework in Chapel"
  authors="Oliver Alvarado Rodriguez, Engin Kayraklioglu, Bartosz Bryg, Mohammad Dindoost, David Bader and Brad Chamberlain"
  description=""
  start="14:20"
  end="14:40"

[discussion2]
  title="Open Community Discussion"
  authors=""
  description=""
  start="14:40"
  end="??"